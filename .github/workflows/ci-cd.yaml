name: CI/CD Pipeline

on:
  push:
    branches: [ master, develop ]
  pull_request:
    branches: [ master ]

env:
  REGISTRY: 025988852505.dkr.ecr.us-east-1.amazonaws.com
  IMAGE_NAME: flask-app
  DOCKERFILE_PATH: app/Dockerfile
  CLUSTER_NAME: flask-devops-cluster
  

jobs:
  # Infrastructure Deployment (only on main branch)
  deploy-infrastructure:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/master'
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.6

    - name: Install kubectl
      uses: azure/setup-kubectl@v4
      with:
        version: 'v1.29.0'

    - name: Install jq and Helm
      run: |
        sudo apt-get update
        sudo apt-get install -y jq
        
        # Install Helm
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        helm version

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Deploy Infrastructure
      run: |
        cd terraform
        terraform init -input=false
        
        # Check for state lock and attempt to unlock
        echo "Checking for state lock..."
        if terraform plan -input=false 2>&1 | grep -q "Error acquiring the state lock"; then
          echo "State lock detected, attempting to force unlock..."
          # Extract lock ID from the error message or try common approaches
          LOCK_ID="8554d007-c9ed-5b92-b788-bd2a074a9eb2"
          echo "Attempting to unlock with ID: $LOCK_ID"
          terraform force-unlock -force "$LOCK_ID" || echo "Force unlock failed, continuing anyway..."
        fi
        
        terraform plan -input=false
        terraform apply -input=false -auto-approve

    - name: Configure kubectl
      run: |
        CLUSTER_NAME=$(cd terraform && terraform output -raw cluster_name)
        aws eks update-kubeconfig --region us-east-1 --name $CLUSTER_NAME

    - name: Deploy Secure Monitoring Stack
      run: |
        echo "ðŸ” Deploying secure monitoring with secrets..."
        
        # Create monitoring namespace
        kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
        
        # Create Grafana admin secret from GitHub Secrets
        kubectl create secret generic grafana-admin-secret \
          --from-literal=admin-user="admin" \
          --from-literal=admin-password="${{ secrets.GRAFANA_ADMIN_PASSWORD }}" \
          --namespace=monitoring \
          --dry-run=client -o yaml | kubectl apply -f -
        
        # Add Helm repository
        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
        helm repo update
        
        # Deploy monitoring with existing secrets
        helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \\
          --namespace monitoring \\
          --create-namespace \\
          --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=20Gi \\
          --set prometheus.prometheusSpec.resources.requests.cpu=500m \\
          --set prometheus.prometheusSpec.resources.requests.memory=1Gi \\
          --set grafana.admin.existingSecret=grafana-admin-secret \\
          --set grafana.admin.userKey=admin-user \\
          --set grafana.admin.passwordKey=admin-password \\
          --set grafana.service.type=ClusterIP \\
          --set alertmanager.enabled=true \\
          --set alertmanager.persistence.enabled=true \\
          --set alertmanager.persistence.size=10Gi \\
          --wait
        
        echo "âœ… Secure monitoring deployed!"
        echo "ðŸ”‘ Grafana credentials: admin / [REDACTED]"
        echo "ðŸ” All secrets managed securely via GitHub Secrets"

    - name: Bootstrap Argo CD (if not exists)
      run: |
        # Check if Argo CD is already installed
        if ! kubectl get namespace argocd &> /dev/null; then
          kubectl create namespace argocd
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
          
          # Wait for Argo CD to be ready
          kubectl wait --for=condition=available deployment/argocd-server -n argocd --timeout=300s
        fi

    - name: Deploy Argo Rollouts
      run: |
        echo "ðŸš€ Installing Argo Rollouts for canary deployments..."
        
        # Create argo-rollouts namespace
        kubectl create namespace argo-rollouts --dry-run=client -o yaml | kubectl apply -f -
        
        # Install Argo Rollouts
        kubectl apply -n argo-rollouts -f https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml
        
        # Wait for Rollouts controller to be ready
        kubectl wait --for=condition=available deployment/argo-rollouts -n argo-rollouts --timeout=300s
        
        echo "âœ… Argo Rollouts installed!"
        echo "ðŸ”§ Canary deployments now available"

    - name: Deploy Root App
      run: |
        # Apply the root application
        kubectl apply -f argo-cd/root-app.yaml
        
        # Install Argo CD CLI
        curl -sSL -o argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
        chmod +x argocd
        sudo mv argocd /usr/local/bin/argocd
        
        # Get Argo CD password and login
        ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
        ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}:8080')
        
        argocd login $ARGOCD_SERVER --username admin --password $ARGOCD_PASSWORD --insecure
        
        # Sync root app
        argocd app sync root-app

    - name: Create GitHub token secret
      run: |
        if ! kubectl get secret github-token -n argocd &> /dev/null; then
          kubectl create secret generic github-token \
            --from-literal=type=github \
            --from-literal=token=${{ secrets.GITHUB_TOKEN }} \
            --namespace=argocd
        fi

  
  # Verify Deployment (GitOps - Argo CD handles actual deployment)
  verify-deployment:
    name: Verify GitOps Deployment
    runs-on: ubuntu-latest
    needs: deploy-infrastructure
    if: github.ref == 'refs/heads/master'
    environment: production

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install kubectl
      uses: azure/setup-kubectl@v4
      with:
        version: 'v1.29.0'

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region us-east-1 --name ${{ env.CLUSTER_NAME }}

    - name: Install Argo CD CLI
      run: |
        curl -sSL -o argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
        chmod +x argocd
        sudo mv argocd /usr/local/bin/argocd

    - name: Check Argo CD sync status
      run: |
        # Get Argo CD password and login
        ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
        ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}:8080')
        
        argocd login $ARGOCD_SERVER --username admin --password $ARGOCD_PASSWORD --insecure
        
        # Wait for apps to sync
        argocd app sync root-app
        argocd app wait root-app --timeout 600

    - name: Verify deployment
      run: |
        # Check Flask app deployment
        kubectl rollout status deployment/flask-app -n flask-app --timeout=300s
        kubectl get pods -n flask-app
        
        # Check monitoring deployment
        kubectl rollout status deployment/prometheus-kube-prometheus-stack-grafana -n monitoring --timeout=300s || true

    - name: Run smoke tests
      run: |
        # Wait for service to be ready
        kubectl wait --for=condition=ready svc/flask-app -n flask-app --timeout=300s || true
        
        # Get service URL
        SERVICE_URL=$(kubectl get svc flask-app -n flask-app -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
        
        if [ -n "$SERVICE_URL" ]; then
          # Run health check
          curl -f http://$SERVICE_URL/health || sleep 30 && curl -f http://$SERVICE_URL/health || true
          
          # Test API endpoints
          curl -f http://$SERVICE_URL/tasks || true
          curl -f http://$SERVICE_URL/metrics || true
        fi

    - name: Notify deployment success
      uses: 8398a7/action-slack@v3
      with:
        status: success
        channel: '#deployments'
        text: 'ðŸš€ Flask app deployed to production via GitOps successfully!'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
